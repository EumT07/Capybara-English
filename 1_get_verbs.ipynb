{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbs Sound / CapybaraEnglish\n",
    "\n",
    "Website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create an Excel file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created an excel file \"verbs.xlsx\", with all verbs, to be able to assemblre all data, in this file I inserted the most used verbs, both irregular and regular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I Needed to get the IPA character for each verb, but first I needed to get all verbs, and then start looking for each verb and get its IPA. \n",
    "\n",
    "So, if I did this, seeking verb by verb, it would take me a long time to get most of them, so I decided to use AI in order to get the information that I wanted and trying to get the ipa in a quick and easy way. \"It wasn't at first\".\n",
    "\n",
    "So I decided to pay for DeepSeep API, but first I needed to have all verbs that I wanted to seek, at the same time, I was learning something related data analyst, and how to use excel, sql and pyton, so I used all that I learned, this really help to develop this process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the process went at the beginning, I started doing this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Install  Virtualenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install virtualenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create virtualenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python -m venv verbsenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd /verbsenv/script/activate.bat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Install openpyxl : To be able to apply and use excel files must install this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Install pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Install Openai to conect with Deepseek API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* install dotenv to read environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Verbos.xlsx\", sheet_name=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get info of Verb table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get regular verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data\n",
    "regular_verbs_infinitive = df[df[\"type\"] == \"REGULAR\"][\"infinitive\"]\n",
    "regular_verbs_present = df[df[\"type\"] == \"REGULAR\"][\"present\"]\n",
    "regular_verbs_past = df[df[\"type\"] == \"REGULAR\"][\"past\"]\n",
    "regular_verbs_present_p = df[df[\"type\"] == \"REGULAR\"][\"present_participle\"]\n",
    "\n",
    "# Inserting into a list\n",
    "r_verbs_list_infinitice = list(regular_verbs_infinitive)\n",
    "r_verbs_list_present = list(regular_verbs_present)\n",
    "r_verbs_list_past = list(regular_verbs_past)\n",
    "r_verbs_list_present_p = list(regular_verbs_present_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get irregular verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data\n",
    "irregular_verbs_infinitive = df[df[\"type\"] == \"IRREGULAR\"][\"infinitive\"]\n",
    "irregular_verbs_present = df[df[\"type\"] == \"IRREGULAR\"][\"present\"]\n",
    "irregular_verbs_past = df[df[\"type\"] == \"IRREGULAR\"][\"past\"]\n",
    "irregular_verbs_past_p = df[df[\"type\"] == \"IRREGULAR\"][\"past_participle\"]\n",
    "irregular_verbs_present_p = df[df[\"type\"] == \"IRREGULAR\"][\"present_participle\"]\n",
    "\n",
    "# Inserting into a list\n",
    "ir_verbs_list_infinitive = list(irregular_verbs_infinitive)\n",
    "ir_verbs_list_present = list(irregular_verbs_present)\n",
    "ir_verbs_list_past = list(irregular_verbs_past)\n",
    "ir_verbs_list_past_p = list(irregular_verbs_past_p)\n",
    "ir_verbs_list_present_p = list(irregular_verbs_present_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===  Verbs  ===\n",
      "Regular Verbs:\t\t 266\n",
      "Irregular Verbs:\t 103\n",
      "Total Verbs:\t\t 369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "===  Verbs  ===\n",
    "Regular Verbs:\\t\\t {len(r_verbs_list_present)}\n",
    "Irregular Verbs:\\t {len(ir_verbs_list_present)}\n",
    "Total Verbs:\\t\\t {len(r_verbs_list_present) + len(ir_verbs_list_present)}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating chunks\n",
    "\n",
    "The idea of creating chunks was to be able to search for verbs by segments.\n",
    "\n",
    "In this part I just wanted to divide the amount of verbs by a number \"n\" to obtain a quantity in which it would be easy for me to seek each verb and correct them, so the idea was to make a list and insert a certain amount of verbs to be able to perform the search with more tranquility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Regular verbs chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Regular Verbs ===\n",
      "Lote: 30\n",
      "List: [26, 56, 86, 116, 146, 176, 206, 236, 266]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# verbs / n = quantity of verbs to seek\n",
    "RV_chunk = round(len(r_verbs_list_present) / 9)\n",
    "\n",
    "# I have created a range of numbers, where we can get a number jump list according to the amount of verbs obtained in the previous step\n",
    "RV_chunks_list = list(range(26,290,30))\n",
    "\n",
    "print(f\"\"\"\n",
    "=== Regular Verbs ===\n",
    "Lote: {RV_chunk}\n",
    "List: {RV_chunks_list}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Irregular verbs chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Iregular Verbs ===\n",
      "Lote: 22\n",
      "List: [15, 37, 59, 81, 103]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# verbs / n = quantity of verbs to seek \n",
    "IV_chunk = round(len(ir_verbs_list_present) / 5) + 1\n",
    "\n",
    "# I have created a range of numbers, where we can get a number jump list according to the amount of verbs obtained in the previous step\n",
    "IV_chunks_list = list(range(15,112,22))\n",
    "\n",
    "print(f\"\"\"\n",
    "=== Iregular Verbs ===\n",
    "Lote: {IV_chunk}\n",
    "List: {IV_chunks_list}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating List of verb to start seeking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Regular List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_r_verbs_infinitive = []\n",
    "list_r_verbs_present = []\n",
    "list_r_verbs_past = []\n",
    "list_r_verbs_present_participle = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Irregular List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ir_verbs_infinitive = []\n",
    "list_ir_verbs_present = []\n",
    "list_ir_verbs_past = []\n",
    "list_ir_verbs_past_p = []\n",
    "list_ir_verbs_present_p = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating function verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVerbs(lotes,verbs,newList):\n",
    "    number = 0\n",
    "    for lote in lotes:\n",
    "        newList.append(verbs[number:lote])\n",
    "        number = lote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filling out regular verb List."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getVerbs(RV_chunks_list,r_verbs_list_infinitice,list_r_verbs_infinitive)\n",
    "getVerbs(RV_chunks_list,r_verbs_list_present,list_r_verbs_present)\n",
    "getVerbs(RV_chunks_list,r_verbs_list_past,list_r_verbs_past)\n",
    "getVerbs(RV_chunks_list,r_verbs_list_present_p,list_r_verbs_present_participle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filling out irregular verb List."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getVerbs(IV_chunks_list,ir_verbs_list_infinitive,list_ir_verbs_infinitive)\n",
    "getVerbs(IV_chunks_list,ir_verbs_list_present,list_ir_verbs_present)\n",
    "getVerbs(IV_chunks_list,ir_verbs_list_past,list_ir_verbs_past)\n",
    "getVerbs(IV_chunks_list,ir_verbs_list_past_p,list_ir_verbs_past_p)\n",
    "getVerbs(IV_chunks_list,ir_verbs_list_present_p,list_ir_verbs_present_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbs_JSON(folder,file,verbs):\n",
    "    # root\n",
    "    root = None\n",
    "\n",
    "    # Make folder : verb-json\n",
    "    folder_path = \"./verb-json\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    if folder == \"regular\":\n",
    "        #regular Folder\n",
    "        regular_root = f\"./verb-json/{folder}\"\n",
    "        os.makedirs(regular_root, exist_ok=True)\n",
    "\n",
    "        #root\n",
    "        root = os.path.join(regular_root,f\"{file}.json\")\n",
    "    else:\n",
    "        #Irregular Folder\n",
    "        irregular_root = f\"./verb-json/{folder}\"\n",
    "        os.makedirs(irregular_root, exist_ok=True)\n",
    "\n",
    "        #root\n",
    "        root = os.path.join(irregular_root,f\"{file}.json\")\n",
    "\n",
    "\n",
    "    with open(root, \"w\") as f:\n",
    "        json.dump([],f)\n",
    "\n",
    "    def insert_JSON(data, fileName = root):\n",
    "        with open(fileName, \"r+\", encoding= \"utf-8\") as file:\n",
    "            file_data = json.load(file)\n",
    "            file_data.append(data)\n",
    "            file.seek(0)\n",
    "            json.dump(file_data, file, indent= 4)\n",
    "\n",
    "    for index,list in enumerate(verbs):\n",
    "        insert_JSON({\n",
    "            f\"List {index + 1}\" : list\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Regular JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_JSON(\"regular\",\"infinitive\",list_r_verbs_infinitive)\n",
    "verbs_JSON(\"regular\",\"present\", list_r_verbs_present)\n",
    "verbs_JSON(\"regular\",\"past\", list_r_verbs_past)\n",
    "verbs_JSON(\"regular\",\"present_participle\", list_r_verbs_present_participle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Irregular JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_JSON(\"irregular\",\"infinitive\",list_ir_verbs_infinitive)\n",
    "verbs_JSON(\"irregular\",\"present\",list_ir_verbs_present)\n",
    "verbs_JSON(\"irregular\",\"past\",list_ir_verbs_past)\n",
    "verbs_JSON(\"irregular\",\"past_participle\",list_ir_verbs_past_p)\n",
    "verbs_JSON(\"irregular\",\"present_participle\",list_ir_verbs_present_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Insert IPA (International Phonetic Alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just copy and paste data from verb-json and insert intro the list called chunk\n",
    "#Example\n",
    "\"\"\"\n",
    "chunk = [\n",
    "    \"ACCEPT\",\n",
    "    \"ACT\",\n",
    "    \"ADD\",\n",
    "    \"ADMIT\",\n",
    "    \"ADVISE\",\n",
    "    \"AFFORD\",\n",
    "    \"AGREE\",\n",
    "    \"AIM\"\n",
    "]\n",
    "\"\"\"\n",
    "chunk = [\n",
    "            \n",
    "]\n",
    "\n",
    "class DeepseekAI():\n",
    "    chunk_list = []\n",
    "    json_list = []\n",
    "    #For use deepSeek create and new apikey and insert here, in order this works in an properly way.!!\n",
    "    api_key = \"<DeepSeek API Key>\"\n",
    "    base_url = \"https://api.deepseek.com/v3\"\n",
    "\n",
    "    def __init__(self, chunk):\n",
    "        self.chunk = chunk\n",
    "        self.searchVerbByDeepSeek()\n",
    "    \n",
    "    def cleanVerbsString(self,verbs):\n",
    "        \"\"\"\n",
    "        There are verbs inside the list like : \"BE-AM-IS-ARE\"\n",
    "\n",
    "        so, list was: [\"ARISE \",\"BE-AM-IS-ARE\",\"BEAR\"]\n",
    "\n",
    "        now, the list will be: [\"ARISE\",\"BE\",\"AM\",\"IS\",\"ARE\",\"BEAR\"]\n",
    "        \"\"\"\n",
    "        for item in verbs:\n",
    "            string = item.split(\"-\")\n",
    "            item_length = len(string)\n",
    "            if( item_length > 1 ):\n",
    "                for x in string:\n",
    "                    self.chunk_list.append(x.strip())\n",
    "            else:\n",
    "                self.chunk_list.append(item.strip())\n",
    "\n",
    "    def searchVerbByDeepSeek(self):\n",
    "        self.cleanVerbsString(self.chunk)\n",
    "        \n",
    "        client = OpenAI(\n",
    "            api_key = self.api_key,\n",
    "            base_url = self.base_url\n",
    "        )\n",
    "\n",
    "        system_promt = \"\"\"\n",
    "        I'm going to provide a list of verbs, and you will be giving me the ipa of these verbs, the ipa that I want to get are IPA UK (British) and IPA US(American), please take these verb and output them in JSON format.\n",
    "\n",
    "        Example Input: [\"ARISE\",\"BE\",\"AM\",\"IS\",\"ARE\",\"BEAR\"]\n",
    "\n",
    "        Example JSON OUTPUT of each verbs:\n",
    "        [\n",
    "            \"ARISE\" : {\n",
    "                \"UK\": [\"/ARISE's Ipa uk/\"],\n",
    "                \"US\": [\"/ARISE's Ipa uk/\"]\n",
    "            },\n",
    "            next verb\n",
    "        ]\n",
    "\n",
    "        \"\"\"\n",
    "        user_promt = f\"Tell me the UK and US ipa of these verbs: {self.chunk_list}\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\" : system_promt},\n",
    "            {\"role\": \"user\", \"content\" : user_promt},\n",
    "        ]\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=messages,\n",
    "            response_format= {\n",
    "                'type': 'json_object'\n",
    "            }\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        I did this part manually chunk by chunk, in order to check that the data I got was right, it took me a few hours, but I got the desired result, so I just copied all info that I got by console into a text file and then create a json with this info.\n",
    "        \"\"\"\n",
    "        print([json.loads(response.choices[0].message.content)])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = DeepseekAI(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Translation of the each verbs: Spanish - Portuguese - French - Italian - German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "            \"TO Be\",\n",
    "            \"To work\"       \n",
    "]\n",
    "\n",
    "class TranslationAI():\n",
    "    verbs = []\n",
    "    json_list = []\n",
    "    json = None\n",
    "    api_key = \"<DeepSeek API Key>\"\n",
    "    base_url = \"https://api.deepseek.com/v3\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.verbs = data\n",
    "        self.searchTranslations()\n",
    "    \n",
    "\n",
    "    def searchTranslations(self):\n",
    "        \n",
    "        client = OpenAI(\n",
    "            api_key = self.api_key,\n",
    "            base_url = self.base_url\n",
    "        )\n",
    "\n",
    "        system_prompt = \"\"\"\n",
    "        I 'm going to give you a list of verbs, and I want you to search each verb and return the translation of the verbs in: Spanish, Portuguese, French, Italian, and German. Provide the information in valid JSON format using double quotes `\"` for keys and string values, if there are verbs with multiple meaning add it as well.\n",
    "\n",
    "        Example INPUT: [\"To Do\", \"To Break\", \"To Get\"]\n",
    "\n",
    "        Example JSON OUTPUT:\n",
    "        [{\n",
    "            \"To Do\": {\n",
    "                \"spanish\": \"hacer\",\n",
    "                \"portuguese\": \"fazer\",\n",
    "                \"french\": \"faire\",\n",
    "                \"italian\": \"fare\",\n",
    "                \"german\": \"machen\"\n",
    "                }\n",
    "        },\n",
    "        {\n",
    "            \"To Break\": {\n",
    "                \"spanish\": \"romper\",\n",
    "                \"portuguese\": \"quebrar\",\n",
    "                \"french\": \"casser\",\n",
    "                \"italian\": \"rompere\",\n",
    "                \"german\": \"brechen\"\n",
    "                }\n",
    "        },\n",
    "        {\n",
    "            \"To Get\": {\n",
    "                \"spanish\": \"conseguir\",\n",
    "                \"portuguese\": \"obter\",\n",
    "                \"french\": \"obtenir\",\n",
    "                \"italian\": \"ottenere\",\n",
    "                \"german\": \"bekommen\"\n",
    "                }\n",
    "        }]\n",
    "        \"\"\"\n",
    "        user_prompt = f\"Give the translation of these verbs: {self.verbs}\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\" : system_prompt},\n",
    "            {\"role\": \"user\", \"content\" : user_prompt},\n",
    "        ]\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=messages,\n",
    "            response_format= {\n",
    "                \"type\": \"json_object\"\n",
    "            }\n",
    "        )     \n",
    "        # self.json_list.append()\n",
    "        self.json = json.loads(response.choices[0].message.content)\n",
    "        self.json = json.dumps(self.json, indent=2)\n",
    "        \n",
    "app = TranslationAI(data)\n",
    "# app.json\n",
    "print(app.json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verbsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
